{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global warming glaciers, cyclones into and droughts. Global crising implies in the averature of gradual\n"
     ]
    }
   ],
   "source": [
    "# Natural Language Processing using Python\n",
    "\n",
    "# N-Gram Modelling - Character Grams\n",
    "# Importing libraries\n",
    "import random\n",
    "\n",
    "# Sample data\n",
    "text = \"\"\"Global warming or climate change has become a worldwide concern. It is gradually developing into an unprecedented environmental crisis evident in melting glaciers, changing weather patterns, rising sea levels, floods, cyclones and droughts. Global warming implies an increase in the average temperature of the Earth due to entrapment of greenhouse gases in the earthâ€™s atmosphere.\"\"\"\n",
    "\n",
    "# Order of the grams\n",
    "n = 3\n",
    "\n",
    "# Our N-Grams\n",
    "ngrams = {}\n",
    "\n",
    "# Creating the model\n",
    "for i in range(len(text)-n):\n",
    "    gram = text[i:i+n]\n",
    "    if gram not in ngrams.keys():\n",
    "        ngrams[gram] = []\n",
    "    ngrams[gram].append(text[i+n])\n",
    "     \n",
    "# Testing our N-Gram Model    \n",
    "currentGram = text[0:n]\n",
    "result = currentGram\n",
    "for i in range(100):\n",
    "    if currentGram not in ngrams.keys():\n",
    "        break\n",
    "    possibilities = ngrams[currentGram]\n",
    "    nextItem = possibilities[random.randrange(len(possibilities))]\n",
    "    result += nextItem\n",
    "    currentGram = result[len(result)-n:len(result)]\n",
    "  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#import nltk\n",
    "s = \"Natural-language processing (NLP) is an area of computer science \" \\\n",
    "    \"and artificial intelligence concerned with the interactions \" \\\n",
    "    \"between computers and human (natural) languages.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(f):\n",
    "    print ('hey one final time i am calling')\n",
    "    def mak(*args, **kwargs):\n",
    "        ngrams = f(*args, **kwargs) #---> generate_ngrams(s, n)\n",
    "        result = [\" \".join(ngram) for ngram in ngrams]\n",
    "        #return ngrams\n",
    "        return result\n",
    "    return mak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey one final time i am calling\n"
     ]
    }
   ],
   "source": [
    "@wrapper\n",
    "def generate_ngrams(s, n):\n",
    "    # Convert to lowercases\n",
    "    s = s.lower()\n",
    "    \n",
    "    # Replace all none alphanumeric characters with spaces\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    \n",
    "    # Break sentence in the token, remove empty tokens\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    #print (tokens)\n",
    "    # Use the zip function to help us generate n-grams\n",
    "    # Concatentate the tokens into ngrams and return\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return (list(ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language processing',\n",
       " 'language processing nlp',\n",
       " 'processing nlp is',\n",
       " 'nlp is an',\n",
       " 'is an area',\n",
       " 'an area of',\n",
       " 'area of computer',\n",
       " 'of computer science',\n",
       " 'computer science and',\n",
       " 'science and artificial',\n",
       " 'and artificial intelligence',\n",
       " 'artificial intelligence concerned',\n",
       " 'intelligence concerned with',\n",
       " 'concerned with the',\n",
       " 'with the interactions',\n",
       " 'the interactions between',\n",
       " 'interactions between computers',\n",
       " 'between computers and',\n",
       " 'computers and human',\n",
       " 'and human natural',\n",
       " 'human natural languages']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ngrams(s, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
